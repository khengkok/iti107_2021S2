{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/nyp-sit/it3103/blob/main/week3/convnets_with_small_datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0RZIgnFFEv5t",
    "tags": []
   },
   "source": [
    "# Lab Exercise: Data Augmentation\n",
    "\n",
    "In our previous exercise with the cats and dogs dataset, our validation accuracy stalls at 75%. Because we only have relatively few training samples (2400), overfitting is going to be our number one concern. Overfitting is caused by having too few samples to learn from, rendering our model to be unable to generalize to new data. Given infinite data, our model would be exposed to every possible aspect of the data distribution at hand: we would never overfit. Data augmentation takes the approach of generating more training data from existing training samples, by \"augmenting\" the samples via a number of random transformations that yield believable-looking images. This helps the model get exposed to more aspects of the data and generalize better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qQgbpqHw-vXy"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train and validation dataset\n",
    "\n",
    "We will go ahead and download the same 'cats and dogs' dataset, and setup the training and validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "dataset_URL = 'https://nyp-aicourse.s3-ap-southeast-1.amazonaws.com/datasets/cats_and_dogs_subset.tar.gz'\n",
    "tf.keras.utils.get_file(origin=dataset_URL, extract=True, cache_dir='.')\n",
    "dataset_folder = os.path.join('datasets', 'cats_and_dogs_subset')\n",
    "\n",
    "batch_size = 16\n",
    "image_size = (128,128)\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_folder,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='binary'\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_folder,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9e9YQpQ8-vYE"
   },
   "source": [
    "## Using Keras Data Augmentation layer\n",
    "\n",
    "\n",
    "Since tensorflow 2.2, Keras has introduced new types of layers for doing image data augmentation, such as Random Cropping, Random Flipping, etc. Previously, we have to depend on `ImageDataGenerator` (which is a lot slower) to do so. Before tensorflow 2.6, they are available as experimental layers (in the `tf.keras.layers.experimental.preprocessing` package), but has been officially supported from tensorflow 2.6 onwards (i.e. available as part of the `tf.keras.layers`).\n",
    "\n",
    "In the code below, we will check the tensorflow version and instantiate the correct layer depending on the version. We use only one RandomRotation layer in the example below. The value `0.3` refers to the maximum rotation angle in both clock-wise and anti-clockwise direction. You can find out more info from the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomRotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vbAfiBdu-vYE"
   },
   "outputs": [],
   "source": [
    "if tf.version.VERSION >= '2.6.0':\n",
    "    data_augmentation = keras.Sequential(\n",
    "        [\n",
    "            keras.layers.RandomRotation(0.3)\n",
    "        ]\n",
    "    )\n",
    "else: \n",
    "    data_augmentation = keras.Sequential(\n",
    "        [\n",
    "            keras.layers.experimental.preprocessing.RandomRotation(0.3)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chGB_tp0OmVI"
   },
   "source": [
    "\n",
    "To see the effects of data augmentation, let us apply our data_augmentation layer to a sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lGJAgFv7OojQ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "images, _ = next(train_ds.take(1).as_numpy_iterator())\n",
    "sample_image = images[0]/255.\n",
    "plt.imshow(sample_image)\n",
    "sample_image = tf.expand_dims(sample_image, 0)\n",
    "print(sample_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3gtBzOgkP3ng"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "for i in range(8):\n",
    "    augmented_image = data_augmentation(sample_image)\n",
    "    ax = plt.subplot(2, 4, i + 1)\n",
    "    plt.imshow(augmented_image[0])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_qiDkZc-vYF"
   },
   "source": [
    "**Exercise 1:**\n",
    "\n",
    "Modify `data_augmention` above to add in [Random Flipping](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomFlip) and [Random Zoom](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomZoom). Choose the appropriate values for the flipping and cropping heights/widths. \n",
    "\n",
    "<details><summary>Click here for answer</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.RandomRotation(0.3),\n",
    "        keras.layers.RandomFlip(mode=\"horizontal\"),\n",
    "        keras.layers.RandomZoom(0.2)\n",
    "    ]\n",
    ")\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GxLPiFmw-vYF"
   },
   "outputs": [],
   "source": [
    "# data_augmentation = ??\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.RandomRotation(0.3),\n",
    "        keras.layers.RandomFlip(mode=\"horizontal\"),\n",
    "        keras.layers.RandomZoom(0.2)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2I6r5H9B-vYF"
   },
   "source": [
    "**Exercise 2:**\n",
    "\n",
    "Modify `make_model()` to apply data augmention layers you have created earlier. Where should you place your augmentation layer?\n",
    "\n",
    "<details>\n",
    "<summary>Click here for answer</summary>\n",
    "\n",
    "```python\n",
    "def make_model():\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(shape=(128, 128, 3)))\n",
    "    model.add(data_augmentation)\n",
    "    model.add(keras.layers.Rescaling(scale=1./255))\n",
    "    ...\n",
    "    ...\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(512, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "model = make_model()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lfk0cqS2YHYj"
   },
   "outputs": [],
   "source": [
    "def make_model():\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    " \n",
    "    model.add(keras.layers.Input(shape=image_size+(3,)))\n",
    "    model.add(data_augmentation)\n",
    "    model.add(keras.layers.Rescaling(scale=1./255))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(32, (3, 3)))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(64, (3, 3)))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(128, (3, 3)))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(128, (3, 3)))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(512, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "model = make_model()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LUsyk60w8Ow5"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5fmnlwSG6vq"
   },
   "source": [
    "Let's train our new model with the data augmentation layer. We will need to train for more epochs, so that our network has better chance of seeing all the original images (since now we cannot guarantee that our original un-augmented image is seen every by our model every epoch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W1eWVr6WKuo9"
   },
   "outputs": [],
   "source": [
    "### Note: the training will take quite a while. We have previously trained the model for 100-epochs.\n",
    "### You can download the checkpoints by uncommenting the following and skip the next cell \"mode.fit()\"\n",
    "\n",
    "# !wget https://nyp-aicourse.s3.ap-southeast-1.amazonaws.com/it3103/checkpoints/week3-1-100epochs.zip\n",
    "# !unzip week3-1-100epochs.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iv2sEKTrYl81"
   },
   "outputs": [],
   "source": [
    "## Comment out this if you just want to use the pretrained weights\n",
    "def create_tb_callback(): \n",
    "\n",
    "    root_logdir = os.path.join(os.curdir, \"tb_logs\")\n",
    "\n",
    "    def get_run_logdir():    # use a new directory for each run\n",
    "        import time\n",
    "        \n",
    "        run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "        return os.path.join(root_logdir, run_id)\n",
    "\n",
    "    run_logdir = get_run_logdir()\n",
    "\n",
    "    tb_callback = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "    return tb_callback\n",
    "\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"best_checkpoint\",\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "model.fit(train_ds, validation_data=val_ds, \n",
    "          epochs=100, \n",
    "          callbacks=[create_tb_callback(), model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KI1D6tyc-HPT"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"best_checkpoint\")\n",
    "model.evaluate(val_ds)\n",
    "\n",
    "model.save(\"cats_dogs_augmented_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRZY8r1O-vYG"
   },
   "source": [
    "Let's visualize our training using Tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5LZDuZaW-vYG"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir tb_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOLypNoy-vYG"
   },
   "source": [
    "Thanks to data augmentation, our model has less overfitting now, as the training curves are more closely tracking the validation \n",
    "curves. We are now able to reach an validation accuracy of about 80%, slightly better than previously.\n",
    "\n",
    "However, it would be very difficult to improve the model any further even with data augmentation. The augmented images are still heavily correlated, since they come from a small number of original images -- we cannot produce new information, we can only remix existing information. As next step to improve our accuracy on this problem, we will have to leverage transfer learning using pre-trained model, which will be the focus of next exercises."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "convnets-with-small-datasets.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
