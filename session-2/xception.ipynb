{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfc46a0d-4718-4a4f-9101-65ce70ff229e",
   "metadata": {},
   "source": [
    "# Practical Exercise (Optional): Create Modern Modular Network \n",
    "\n",
    "In this exercise, you are going to make use of some architecural elements that you learnt, such as residual connection, and separable convolution, and combine them into a building block, and use this building block to construct a modular network. \n",
    "\n",
    "This building block is similar to what [Xception](https://arxiv.org/abs/1610.02357) is using. \n",
    "\n",
    "Here is the simplified view of our network: \n",
    "\n",
    "![xception](https://nyp-aicourse.s3.ap-southeast-1.amazonaws.com/iti107/resources/mini_xception.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152199e4-56a2-4e03-ba75-d4ad12e6312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e403eff-1641-4eb6-8b29-56b124e86156",
   "metadata": {},
   "source": [
    "**Exercise 1**\n",
    "\n",
    "Let us the define our xception block first. Here are the steps you will need to do: \n",
    "1. First save the output from previous block (or if this is the first block, then output from previous convolutional/maxpooling layer) and use this as skip connection to be added later\n",
    "2. Add the 2 separable convolutional and the maxpool layer. \n",
    "3. Add BatchNormalization after each separable convolutional layer (as practiced by modern architecture).  You can add BatchNormalization before or after Activation layer.\n",
    "4. Use 1x1 conv to change the depth of the skip connection to match that of the rest of layers and add the skip connection to the output from MaxPooling layer. You will also need to reduce the size to match the output from MaxPooling layer, by using a stride size of 2\n",
    "5. As recommended by author of ResNet, the skip connection should be added before the Activation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79f86c8-54bb-4bdc-b4c6-31344cbfb16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xception_block(x, depth): \n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    x: output from the previous block or previous layer, considered as input to this Xception block\n",
    "       it is a tensor of shape (batch, h, w, channels)\n",
    "    depth: number of channels, it is an int value\n",
    "    \"\"\"\n",
    "    \n",
    "    # save input to be used as skip connection\n",
    "    skip_connection = ?\n",
    "    \n",
    "    # add the first separable convolutional 2D layer\n",
    "    x = ?\n",
    "    \n",
    "    # add the second separable convolutional 2D layer, without the activation layer\n",
    "    x = ?\n",
    "    \n",
    "    # add the maxpooling 2d layer, with stride of 2\n",
    "    x = ?\n",
    "    \n",
    "    # adjust the size and depth using 1x1 convolution to match the output from last maxpooling layer\n",
    "    residual = ?\n",
    "    \n",
    "    # add the skip connection \n",
    "    x = layers.add([x, residual])  # Add back residual\n",
    "    \n",
    "    # add the activation layer\n",
    "    x = ?\n",
    "    \n",
    "    return x # Set aside next residual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c566012b-eb2f-45cd-a60e-826a7a9de9ea",
   "metadata": {},
   "source": [
    "**Exercise 2:**\n",
    "\n",
    "We will then build our complete network using the xception block defined in the previous exercise: \n",
    "1. Define the input layer with appropriate shape\n",
    "2. Define a rescaling layer to normalize the input to (0,1)\n",
    "3. Define the entry blocks that consist of 2 convolutional 2D layers \n",
    "4. Add the series of xception blocks, with different depths `[128,256,512,728]`\n",
    "5. Add the last Separable convolutional 2D layer \n",
    "6. Add GlobalAveragePooling2D layer before connected to output Dense Layer\n",
    "7. Use Dropout for the dense layer \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c4052d-f8dc-4602-a61f-fd648b9ea40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape, num_classes): \n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Entry block\n",
    "    x = ?\n",
    "    \n",
    "    # build a series of xception blocks with different sizes\n",
    "    for size in [128, 256, 512, 728]:\n",
    "        x = ?? \n",
    "    \n",
    "    outputs = ?\n",
    "    \n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7bca3d-037a-4c1e-bc96-8afbcda7053c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (128,128)\n",
    "\n",
    "model = make_model(input_shape= image_size + (3,), num_classes=2)\n",
    "\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20393c0b-8e73-47d7-a371-70c61e58cbde",
   "metadata": {},
   "source": [
    "### Create train and validation dataset\n",
    "\n",
    "We will go ahead and download the same dataset, and setup the training and validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6c6756-58cd-442f-9c4e-88f31b0a7131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "dataset_URL = 'https://nyp-aicourse.s3-ap-southeast-1.amazonaws.com/datasets/cats_and_dogs_subset.tar.gz'\n",
    "tf.keras.utils.get_file(origin=dataset_URL, extract=True, cache_dir='.')\n",
    "dataset_folder = os.path.join('datasets', 'cats_and_dogs_subset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4977bfe2-d84f-4512-9a70-462e57a8cd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_folder,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='binary'\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_folder,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b848e43d-38e2-4fe8-a73b-2eccc29777ef",
   "metadata": {},
   "source": [
    "Ok, everything is ready. Now we are ready to put our mini-xception network to test and see if perform better than our previous 'traditional' CNN architecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19cb509-ba47-4abe-8888-6bfb01cf493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tb_callback(): \n",
    "\n",
    "    import os\n",
    "    \n",
    "    root_logdir = os.path.join(os.curdir, \"tb_logs\")\n",
    "\n",
    "    def get_run_logdir():    # use a new directory for each run\n",
    "        \n",
    "        import time\n",
    "        \n",
    "        run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "        return os.path.join(root_logdir, run_id)\n",
    "\n",
    "    run_logdir = get_run_logdir()\n",
    "\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "    return tb_callback\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"bestcheckpoint\",\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "\n",
    "# compile our model with loss and optimizer \n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    train_ds, epochs=30, \n",
    "    validation_data=val_ds,\n",
    "    callbacks=[model_checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0985069-c506-479b-a84e-1e2e5d819de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoint = 'bestcheckpoint'\n",
    "\n",
    "model.load_weights(best_checkpoint)\n",
    "model.evaluate(val_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
