{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "train convnet with custom data (solution)",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyp-sit/iti107/blob/main/session-1/train_convnet_with_custom_data_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6gHiH-I7uFa"
      },
      "source": [
        "# Exercise: Using Convolutional Neural Network for Custom Data\n",
        "\n",
        "In this exercise, you will apply what you learnt in the previous lab and apply it on a more realistic dataset (as compared to the toy dataset such as Fashion MNIST). Also, you will learn to create `tf.data.Dataset` and use them for training.\n",
        "\n",
        "We will be using a smaller subset of the original [Cats vs. Dogs dataset] (https://www.kaggle.com/c/dogs-vs-cats/data) from Kaggle. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvWMjo-aEx9I"
      },
      "source": [
        "## Download the dataset\n",
        "\n",
        "Download the dataset from https://nyp-aicourse.s3-ap-southeast-1.amazonaws.com/datasets/cats_and_dogs_subset.tar.gz and unzip into a folder. You can use [tf.keras.utils.get_file()](https://www.tensorflow.org/api_docs/python/tf/keras/utils/get_file) which will download and unzip for you, or just run wget and unzip using bash.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQw0U8lFEx9I"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0tFgT1MMKi6"
      },
      "source": [
        "## Complete your code here \n",
        "dataset_URL = 'https://nyp-aicourse.s3-ap-southeast-1.amazonaws.com/datasets/cats_and_dogs_subset.tar.gz'\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs_subset.tar.gz', origin=dataset_URL, extract=True, cache_dir='.')\n",
        "dataset_dir = os.path.join(os.path.dirname(path_to_zip), \"cats_and_dogs_subset\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqYGEwlv9jlP"
      },
      "source": [
        "dogs_dir = os.path.join(dataset_dir, \"dogs\")\n",
        "cats_dir = os.path.join(dataset_dir, \"cats\")\n",
        "print('total dog images:', len(os.listdir(dogs_dir)))\n",
        "print('total cat images:', len(os.listdir(cats_dir)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkhD1u25Ex9J"
      },
      "source": [
        "## Generate Datasets\n",
        "\n",
        "Generates a training and validation dataset from image files in the directory. In the previous exercise, when we use `keras.datasets` to load the Fashion MNIST dataset, the data are already splitted to train and test(validation) set and are loaded as numpy array. However, if you are working with your own dataset, you will probably have a bunch of image files in a filesystem and you will need to do your train/test split. Also, if you have a large dataset, it is not efficient to make all the images loaded as numpy array, as you will probably run out of memory soon. A more efficient way is to use [`tf.data.Datasets`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) API to load the data (recommended way). \n",
        "\n",
        "Keras provides an easy-to-use function [image_dataset_from_directory](https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory) that behaves like the old good [ImageDataGenerator](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) but uses the more efficient `tf.data.Datasets`\n",
        "\n",
        "You will need to organize your images into a folder structure like shown here. Assuming you have two classes A and B, your folder should look like below: \n",
        "\n",
        "```\n",
        "data\n",
        "  classA\n",
        "    imageA1.jpg\n",
        "    imageA2.jpg \n",
        "  classB\n",
        "    imageB1.jpg\n",
        "    imageB2.jpg\n",
        "```\n",
        "\n",
        "You can then use the following code to create a training dataset and validation dataset, both as tf.data.Dataset: \n",
        "\n",
        "```python\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"data\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=1337,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"data\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=1337,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOH6_TyoEx9J"
      },
      "source": [
        "# Complete your code here \n",
        "\n",
        "# specify the desired input size to the convolutional neural network\n",
        "image_size = (200, 200)\n",
        "\n",
        "# specify the training batch size\n",
        "batch_size = 16\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    dataset_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=1337,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    dataset_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=1337,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_-T5V0dG9Kr"
      },
      "source": [
        "\n",
        "The label will be inferred from the name of the subdirectory `classA (label 0)` and `classB (label 1)`, where the numeric label is assigned according to alphanumeric order.   \n",
        "\n",
        "You can look at the assignment using the `class_names` variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sQy4NuRGlOn"
      },
      "source": [
        "train_ds.class_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tB86lOruEx9K"
      },
      "source": [
        "## Visualize sample images from your train or validation dataset\n",
        "\n",
        "Visualize some of the images in training dataset.  Also find out what label (0 or 1) is given to cat and dog respectively. You can use the `take(1)` method of `tf.data.Dataset` to take 1 batch of samples (image + label). You can then iterate over this to retrieve each sample. For example: \n",
        "\n",
        "```python\n",
        "for images, labels in train_ds.take(1): \n",
        "    for i in range(len(images): \n",
        "       ## do something \n",
        "       \n",
        "```\n",
        "\n",
        "You can also convert the dataset into a list if you prefer to work with list. For example: \n",
        "\n",
        "```python\n",
        "samples = list(train_ds.take(1))\n",
        "images, labels = samples[0]   \n",
        "\n",
        "```\n",
        "\n",
        "`samples[0]` is a tuple and the length of the images and labels is the batch size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tgw94jREx9K"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# complete your code here\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "\n",
        "# loop through the batch of samples and display them \n",
        "for images, _ in train_ds.take(1):\n",
        "    for i in range(8):\n",
        "        ax = plt.subplot(2, 4, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Om3eCKWbWm8i"
      },
      "source": [
        "## Build your Model\n",
        "\n",
        "Build your model and compile your model with appropriate loss function and optimizer. You can choose any combination of layers and units but observe general design pattern (e.g. VGG-16). Also try to use the functional API instead of sequential API. \n",
        "\n",
        "In our previous exercise, we normalize our numpy array (images) to between 0 and 1, as a separate pre-processing step. You can make scaling as part of the model layer so that the scaling can be done as part of the model to take advantage of any GPU acceleration (if available). Keras provides [`Rescaling` layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Rescaling) for this purpose.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo5I3C0rEx9L"
      },
      "source": [
        "## complete your code here, use functional API model\n",
        "\n",
        "image_size = (200, 200, 3)\n",
        "\n",
        "def make_model():\n",
        "\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Input(shape=image_size))\n",
        "    model.add(keras.layers.Rescaling(scale=1./255))\n",
        "    model.add(keras.layers.Conv2D(32, (3, 3)))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.Activation('relu'))\n",
        "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
        "    model.add(keras.layers.Conv2D(64, (3, 3)))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.Activation('relu'))\n",
        "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
        "    model.add(keras.layers.Conv2D(128, (3, 3)))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.Activation('relu'))\n",
        "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
        "    model.add(keras.layers.Conv2D(128, (3, 3)))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.Activation('relu'))\n",
        "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
        "    model.add(keras.layers.Flatten())\n",
        "    model.add(keras.layers.Dense(512, activation='relu'))\n",
        "    model.add(keras.layers.Dropout(0.5))\n",
        "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    return model\n",
        "\n",
        "model = make_model()\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGllb4wvWm8l"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "Train your model. Specify the callbacks you want (e.g. Tensorboard, ModelCheckpoint, etc).  \n",
        "As you will be using `tf.data.Dataset` as your dataset, instead of images and labels arrays, you can call your `model.fit()` by simply \n",
        "`model.fit(train_ds, validation_data=val_ds, ....)` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uKL5rx_Ex9L"
      },
      "source": [
        "# Complete your code here\n",
        "\n",
        "def create_tb_callback(): \n",
        "\n",
        "    root_logdir = os.path.join(os.curdir, \"tb_logs\")\n",
        "\n",
        "    def get_run_logdir():    # use a new directory for each run\n",
        "\t    import time\n",
        "\t    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
        "\t    return os.path.join(root_logdir, run_id)\n",
        "\n",
        "    run_logdir = get_run_logdir()\n",
        "\n",
        "    tb_callback = keras.callbacks.TensorBoard(run_logdir)\n",
        "\n",
        "    return tb_callback\n",
        "\n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=\"best_checkpoint\",\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "model.fit(\n",
        "    train_ds,\n",
        "    epochs=30,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[create_tb_callback(), model_checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvQ_XIfTBQQU"
      },
      "source": [
        "model.load_weights('best_checkpoint')\n",
        "model.evaluate(val_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjeLArHYpWoS"
      },
      "source": [
        "model.save('cats_dogs_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wo9XVvMPWm8m"
      },
      "source": [
        "## Visualize the training and validation loss\n",
        "\n",
        "Visualize your training and validation loss. What do you observe? Is there any overfitting/underfitting problem? Modify your model to address the problem, if any."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSR5hMLsWm8n"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir tb_logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1yW9s8KpWoT"
      },
      "source": [
        "## Test out our Model !\n",
        "\n",
        "Let's try out our model.  Download some cats and dogs images from Internet and test it with your model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRuGmaT3FO-u"
      },
      "source": [
        "import ipywidgets as widgets\n",
        "\n",
        "uploader = widgets.FileUpload(\n",
        "    accept='image/*',  # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n",
        "    multiple=False  # True to accept multiple files upload else False\n",
        ")\n",
        "\n",
        "display(uploader)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6l-DPqJFkKF"
      },
      "source": [
        "key = next(iter(uploader.value))\n",
        "\n",
        "with open(key, \"w+b\") as file:\n",
        "    file.write(uploader.data[0])\n",
        "\n",
        "img = tf.keras.preprocessing.image.load_img(\n",
        "    key, target_size=image_size\n",
        ")\n",
        "\n",
        "# we convert the image to numpy array\n",
        "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "# Although we only have single image, however our model expected data in batches\n",
        "# so we will need to add in the batch axis too\n",
        "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "\n",
        "# we load the model saved earlier and do the inference \n",
        "model = keras.models.load_model(\"cats_dogs_model')\n",
        "\n",
        "if predictions[0] > 0.5: \n",
        "    print('It is a dog')\n",
        "else:\n",
        "    print('It is a cat')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}